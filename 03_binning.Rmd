# Binning 

In metagenomics, binning is the process of grouping reads or contigs and assigning them to individual genome known as Metagenome Assembled Genome (MAG). Coverage-based binning approaches will require you to map reads to assembled contigs. 

[Comparision of different binning tools](https://bitbucket.org/berkeleylab/metabat/wiki/Home)

## Mapping 

Mapping allows you to get a rough count of the total number of reads mapping to each contig, also referred to as the depth file or read coverage. This information is required for most binning algorithm. Raw reads from each sample are mapped to the contigs (assembled reads).The idea being that if two contigs come from the same genome in your sample, so the same organism, then they would have been sequenced roughly to the same depth, they would have a similar coverage and they go together. It gets even better if you have multiple samples that vary a bit and you sequence all of them. You do your assembly on one of the samples, then you can take the reads from the other samples, map to that genome (metagenomic assembly) and you can use that as additional information. 

Start by creating a new directory with all your assembled contigs and your interleave.trim.fastq. Different tools exists for mapping reads to genomic sequences. Here we are using `Scons wrapper`. 

### Scons Wrapper (genome mapping)
[Github](https://github.com/imrambo/genome_mapping)

This wrapper maps **FASTQ** reads against an assembly (e.g. genome) in **FASTA** format using BWA-MEM. This wrapper does not produce huge intermediate files (e.g. unfiltered SAM). 

For each sample, create a folder and copy into this folder these two files : the **long contig.fa** (1000 or 2000 bp) and the **trim and interleaved fastq** (fastq after sickle)

1. Go to your home directory and clone the git repository 

```{bash, highlight=TRUE, eval=FALSE}
git clone https://github.com/imrambo/genome_mapping.git
```

2. Go to the new directory created `genome_mapping` and activate the scons_maps conda environment
```{bash, highlight=TRUE, eval=FALSE}
conda activate scons_map
```

3. Run a dry run to ensure everything runs smoothly (you must run this from the `genome_mapping` directory)
```{bash, highlight=TRUE, eval=FALSE}
scons --dry-run --fastq_dir=/home/kvilleneuve/Metagenomic_analyses/mapping/V01_2/ --assembly=/home/kvilleneuve/Metagenomic_analyses/mapping/V01_2/V01_2_1000bp.fa --outdir=/home/kvilleneuve/Metagenomic_analyses/mapping/V01_2/output --sampleids=V01_2_S7_L001_R1_001.fastq.interleave.fastq.trim.fastq --align_thread=5 --samsort_thread=5 --samsort_mem=768M --nheader=8 --tmpdir=/home/kvilleneuve/tmp --logfile=mapping.log
```

4. Run the script from the `genome_mapping` directory. 

--fastq_dir=directory where the interleave_trim_fastq and assembled_long_contig_fasta files are.

--assembly=path to the assembled_long_contig_fasta files. Must include the name of the file at the end. 

--sampleids=the name of the interleave_trim_fastq. 

```{bash, highlight=TRUE, eval=FALSE}
scons --fastq_dir=/home/kvilleneuve/Metagenomic_analyses/mapping/V01_2/ --assembly=/home/kvilleneuve/Metagenomic_analyses/mapping/V01_2/V01_2_1000bp.fa --outdir=/home/kvilleneuve/Metagenomic_analyses/mapping/V01_2/output --sampleids=V01_2_S7_L001_R1_001.fastq.interleave.fastq.trim.fastq --align_thread=5 --samsort_thread=5 --samsort_mem=768M --nheader=8 --tmpdir=/home/kvilleneuve/tmp --logfile=mapping.log
```

In the specified output directory you will find a `.sorted.bam` which contains the depth information required for mmgenome and metabat. 

<font color='red'>Currently looking for a way to loop this. Tried specifying only the input folder and the sampleids as proposed in the README but it does not work. `sampleids` **must** be the exact name as the `fastq` or `fastq.gz` file.</font>

## Depth file

The depth allows you to know how many sequence you can align with certain sections of your contigs. Section with very little depth (few sequences) are not reputable to use. We use the script `jgi_summarize_bam_contig_depths`.  

Move all the `sorted.bam` files into a new folder called `Sorted_Bam` and from this folder use nohup to run the script `jgi_summarize_bam_contig_depths`. 

```{bash}
#!/bin/bash
for i in *.sorted.bam
  do /home/SCRIPT/jgi_summarize_bam_contig_depths --outputDepth $i.depth.txt --pairedContigs $i.paired.txt $i
done 
```

## Create bins  

### MetaBAT2 

[Github](https://bitbucket.org/berkeleylab/metabat/src/master/) / [Article](https://peerj.com/articles/1165/)
Efficient tool for accurately reconstructing single genomes from complex microbial communities

MetaBAT2 requires that your python environment be activate (base). If required, first deactivate `scons_map` and then activate conda
```{bash}
conda deactivate
conda activate
```

In order to be able to loop this for all my samples, I renamed each depth file in the following format : `sample1.fa.depth.txt`. The output is a folder called `bins_dir` containing all the bins created. I recommend using nohup as the binning process can be very long. 

**copy all your 1kb or 2 kb fasta into the folder containing the depth file. 

**Multiple samples**
```{bash}
#!/bin/bash
for i in *.fa
  do metabat2 -i $i -a $i.depth.txt -o bins -t 0 --minCVSum 0 --saveCls -d -v --minCV 0.1 -m 2000
done 
```

`minCVsum` : assigning number of tetranucleotide frequency graphs, donâ€™t grab negative numbers 
`-m` : min size of contig to be considered for binning

# Bin quality  {.tabset}
## Checkm
[Github](https://github.com/Ecogenomics/CheckM/wiki)

**You have to go back one folder in the terminal as checkm will run on all the files in the folder you give it as input. Checkm will automatically create a folder called checkm in the specified directory, therefor if you must run checkm again make sure to delete the newly created checkm folder, otherwise checkm will give you an error message.** 

You  need to specify the extension of your file for it to work. For example, for file finishing is `.fa` the command will be `checkm lineage_wf -x fa`... 

If checkm is already installed on your system simply activate the environment
```{bash, highlight=TRUE, eval=FALSE}
conda activate checkm
```
Run checkm using nohup 
```{bash, highlight=TRUE, eval=FALSE}
checkm lineage_wf -x fa 2kbp_bins/ 2kbp_bins/checkm -f 2kbp_bins/output.txt -t 48 
```

checkm lineage_wf -x fa 1500bp_bins 1500bp_bins/checkm -f 1500bp_bins/output.txt -t 48 --noAdd

a. Open the `output.txt` document with excel to verify the **completeness** and **contamination** of your bins. 
**Standard : Completeness > 50 % and Contamination < 10 %**

b. Remove all the spaces with `control` + `H`

c. Filter the columns by Completeness, and separate the ones < 50 % by adding a line in excel 

d. Filter by Contamination, and highlight all the ones > 10 % - These are the bins you want to clean

## Installing Checkm 
Install Checkm using the [Installation through Conda](https://github.com/Ecogenomics/CheckM/wiki/Installation#how-to-install-checkm) steps. 
After installation is complete run the following to inform where the checkm databases are installed*:
```{bash, highlight=TRUE, eval=FALSE}
checkm data setRoot /usr/local/lib/checkm
```

*I downloaded the [checkm databases](https://data.ace.uq.edu.au/public/CheckM_databases/) and moved them to /usr/local/lib/checkm. 
I decompressed the file using `sudo tar -xf checkm_data_2015_01_16.tar.gz`. 
I changed the File Ownership to root `sudo chown -R root /usr/local/lib/checkm` and Group Ownership to me `sudo chgrp kvilleneuve /usr/local/lib/checkm`. 
I ran the following to inform CheckM of where the files have been placed: `checkm data setRoot /usr/local/lib/checkm`


# Bin cleaning 

## Vizbin 

# Taxonomy 

## GTDBTK
[Github](https://github.com/Ecogenomics/GTDBTk)

Activate the GTDBTK environment
```{bash, highlight=TRUE, eval=FALSE}
conda activate gtdbtk-2.1.1
``` 

I located the folder with the untar GTDBTK data (GTDBTk_data/release214) and I added the path to this file to my ~/.profile (using vi)
```{bash, highlight=TRUE, eval=FALSE}
export GTDBTK_DATA_PATH=/home/genomics/release214
```

In the folder with all your clean and completed genomes run this command with nohup

```{bash, highlight=TRUE, eval=FALSE}
#!/bin/bash
gtdbtk classify_wf --cpus 20 --genome_dir /home/kvilleneuve/Shotgun_Project/saumure/05_binning/complete_bins_1500bp --out_dir /home/kvilleneuve/Shotgun_Project/saumure/05_binning/complete_bins_1500bp/gtdbk_output -x fa
```


Once it is done running, you can open the folder called `gtdbk_output` and copy the folder `gtdbtk.bac120.summary.tsv` to your local computer in order to open it with excel. Use this folder to identify the phylum, class, order, family and genus that you need to download in order to construct your tree. 

## BAsic Rapid Ribosomal RNA Predictor (Barrnap) 
[Github](https://github.com/tseemann/barrnap)

Barrnap predicts the location of ribosomal RNA genes in genomes. It supports bacteria (5S,23S,16S), archaea (5S,5.8S,23S,16S), metazoan mitochondria (12S,16S) and eukaryotes (5S,5.8S,28S,18S). You can run barrnap on both the assembled contigs (community) and MAGs. 

Add the name of the sample at the beginning of every contig and change the file type to `.fna`. Then for each of your file, change the space between the name and the scaffhold number to an underscore

```{bash, highlight=TRUE, eval=FALSE}
for i in *.fa ; do  perl -lne 'if(/^>(\S+)/){ print ">$ARGV $1"} else{ print }' $i > $i.fna ; done
sed -i 's/ /_/g' *.fna
```
Run barrnap
```{bash, highlight=TRUE, eval=FALSE}
barrnap 1kb.fasta.fna > barrnap_hits.txt --threads 20
```
One very useful tool or parsing GFF files is called BEDtool (to install:sudo apt install bedtools). There are many different utilities in bedtools. Here we will want to use the "getfasta" option, which will allow us to supply the fasta file and the barrnap GFF file to obtain the rRNA sequences. Note that the GFF file has the coordinates of where the rRNA genes are encoded, so between the GFF file and the .FNA file we have all the information we need. 
```{bash, highlight=TRUE, eval=FALSE}
bedtools getfasta -fi 1kb.fasta.fna -bed barrnap_hits.gff -fo out.rRNA.fasta
```

Use NCBI-BLAST to classify the rRNA sequences identified by barrnap. 
